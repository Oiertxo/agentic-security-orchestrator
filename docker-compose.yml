services:
  orchestrator:
    build:
      context: .
      dockerfile: services/orchestrator/Dockerfile
    container_name: orchestrator_container
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src
      - ./data/logs:/data/logs
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - MODEL_NAME=hermes3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - internal_network

  kali-engine:
    build:
      context: .
      dockerfile: services/recon-engine/Dockerfile
    container_name: kali-tools-container
    ports:
      - "5000:5000"
    networks:
      - internal_network

networks:
  internal_network:
    driver: bridge