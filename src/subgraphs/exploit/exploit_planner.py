from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from src.model import get_model
from src.state import AgentState, ExploitState, PlannerOutput
from src.schemas import ExploitPlannerSchema
from src.utils import load_prompt, get_clean_content, last_n_messages
from src.logger import logger
from typing import Dict, Any, cast
from langfuse import observe
import json

@observe(name="Exploit planner")
def exploit_planner_node(state: AgentState) -> AgentState:
    llm = get_model()
    system_prompt = load_prompt("exploit.txt")

    exploit_state = state.get("exploit") or {}
    recon_state = state.get("recon") or {}

    logger.info(f"[EXPLOIT_PLANNER] State received: {state}")
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("system", "Port map (host: open ports): {port_map}"),
        ("system", "Intelligence (Known Vulnerabilities): {vulnerabilities}"),
        ("system", "Current Working Target: {working_target}"),
        ("system", "Execution Results: {results}"),
        ("system", "Attempted actions: {attempted}"),
    ])

    planner_input = {
        "port_map": recon_state.get("port_map") or {},
        "results": exploit_state.get("results") or [],
        "attempted": exploit_state.get("attempted") or [],
        "vulnerabilities": exploit_state.get("vulnerabilities") or {},
        "working_target": exploit_state.get("working_target") or {},
    }

    logger.info(f"[EXPLOIT_PLANNER] Calling LLM with intel: {len(planner_input['vulnerabilities'])} service(s) analyzed.")
    
    chain = (prompt | llm.with_structured_output(ExploitPlannerSchema, method="json_mode", strict=True)).with_types(
        input_type=Dict[str, Any],
        output_type=ExploitPlannerSchema,
    )

    # IN PROGRESS
    if len(planner_input['vulnerabilities']) > 0:
        new_exploit: ExploitState = {
            **exploit_state,
            "finished": True,
        }

        return {
            **state,
            "exploit": new_exploit,
            "messages": state.get("messages") + [HumanMessage(content="Vulnerabilities found.")],
            "next_step": "supervisor"
        }

    try:
        result = ExploitPlannerSchema.model_validate(chain.invoke(planner_input))
        data = result.model_dump(mode="json")
    except Exception as e:
        logger.error(f"[EXPLOIT_PLANNER] Parsing error: {e}")
        data = {"finished": True, "next_tool": None, "arguments": {}}

    logger.info(f"[EXPLOIT_PLANNER] Response from LLM: {data}")
    
    if not data or (not data.get("finished") and not data.get("next_tool")):
        logger.error(f"[EXPLOIT_PLANNER] Planner failed to reason. Forcing termination")
        data = {
            "finished": True,
            "next_tool": None,
            "arguments": {},
            "thought": "Forced finish: LLM returned empty or invalid plan."
        }

    is_finished = data.get("finished", False)

    new_exploit: ExploitState = {
        **exploit_state,
        "planner": cast(PlannerOutput, data),
        "finished": is_finished,
    }

    return {
        **state,
        "exploit": new_exploit,
        "messages": state.get("messages") + [AIMessage(content=json.dumps(data))],
        "next_step": "supervisor" if is_finished else "executor"
    }